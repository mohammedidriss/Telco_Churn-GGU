{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GQXfUzOY4eTcJ1-qi9UWQYe0uduEUIDC",
      "authorship_tag": "ABX9TyOgknyvLrrsAvOGiEOiEgWG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammedidriss/AWS-Machine-Learning/blob/master/Telco_Churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3TzuQmDcKro"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv('/content/drive/MyDrive/GGU/TelcoChurn.csv')\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe(include='all'))\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "zGuY41QOR5JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove missing rows and duplicate value and remove total charges that are equal to zero\n",
        "\n",
        "# Remove rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Remove rows where 'TotalCharges' is equal to zero\n",
        "df = df[df['TotalCharges'] != 0]\n",
        "\n",
        "# Make sure TotalChareges has a numeric value\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "104kuJMYjihm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['SeniorCitizen']=df['SeniorCitizen'].astype(bool)\n",
        "df['SeniorCitizen'].dtype #//check if code is working\n",
        "df['TotalCharges']=pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Remove rows with missing TotalCharges\n",
        "df = df.dropna(subset=[\"TotalCharges\"])\n",
        "df.drop_duplicates(inplace=True) # Remove duplicates\n",
        "df.describe()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gyjgIktkgFoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a chart that shows the amount of churn customers, show the percentage\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Calculate churn rate\n",
        "churn_rate = df['Churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Create the chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Churn', data=df)\n",
        "plt.title('Customer Churn')\n",
        "plt.xlabel('Churn')\n",
        "plt.ylabel('Number of Customers')\n",
        "\n",
        "# Add percentage labels to the bars\n",
        "for i, v in enumerate(df['Churn'].value_counts()):\n",
        "    plt.text(i, v + 5, f'{churn_rate[i]:.1f}%', ha='center')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hELJFjpSM3fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  show the demographics of the data points for gender, seniorcitizen, dependent, and partner, and tenure. plot all of them on charts\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Demographics analysis and plotting\n",
        "\n",
        "# Gender distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='gender', data=df)\n",
        "plt.title('Gender Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Senior Citizen distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='SeniorCitizen', data=df)\n",
        "plt.title('Senior Citizen Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Partner distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Partner', data=df)\n",
        "plt.title('Partner Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Dependents distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Dependents', data=df)\n",
        "plt.title('Dependents Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Tenure distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['tenure'], bins=20)\n",
        "plt.title('Tenure Distribution')\n",
        "plt.xlabel('Tenure (months)')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oPqpe5EXN8Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(y=df['TotalCharges'])\n",
        "plt.title('Box Plot of TotalCharges')\n",
        "plt.ylabel('TotalCharges')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "MqTCh8W_BIp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# test, calculate quantiles and see if there is any outliers - different method than the above box plot:\n",
        "Q1 = df['TotalCharges'].quantile(0.25)\n",
        "Q3 = df['TotalCharges'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)]\n",
        "print(outliers)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "phm-oCDrBPUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get feature importance and list the most important features\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "# Convert categorical features to numerical using one-hot encoding\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print the most important features\n",
        "print(feature_importance_df.head(10)) # Print top 10 features\n"
      ],
      "metadata": {
        "id": "MieVb6MoTdPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot and check Tenure vs Chrun - help to understand the population of churners.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # set figure size\n",
        "\n",
        "plt.subplot(2, 2, 1)  # Create a subplot (2 rows, 2 columns, first plot)\n",
        "sns.histplot(df['tenure'], kde=True)\n",
        "plt.title('Distribution of Tenure')\n",
        "\n",
        "plt.subplot(2, 2, 2)  # Second plot\n",
        "sns.countplot(x='Churn', data=df)\n",
        "plt.title('Churn Count')\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)  # 3rd plot\n",
        "sns.boxplot(x='Churn', y='tenure', data=df)\n",
        "plt.title('Tenure vs. Churn')\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 4)  # 4th plot\n",
        "#  Scatter plot of tenure vs. MonthlyChargers, the dotted chart shows the distribution of the customers/churn\n",
        "sns.scatterplot(x='tenure', y='MonthlyCharges', hue='Churn', data=df)\n",
        "plt.title('Tenure vs MonthlyCharges (Colored by Churn)')\n",
        "\n",
        "plt.tight_layout() # prevent overlapping\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PjvcEhr0jYoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the Churn Rate by Tenure - helps to see which customers are leaving whether people who has long tenure or not\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='tenure', y='Churn', data=df, estimator='mean')\n",
        "plt.title('Churn Rate by Tenure')\n",
        "plt.ylabel('Churn Rate')\n",
        "plt.xlabel('Tenure (months)')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Monthly Charges vs. Churn - is the cost a reason for people to churn? is it expensive or not\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Churn', y='MonthlyCharges', data=df)\n",
        "plt.title('Monthly Charges vs. Churn')\n",
        "plt.ylabel('Monthly Charges')\n",
        "plt.xlabel('Churn')\n",
        "plt.show()\n",
        "\n",
        "# plot Contract Type vs. Churn helps to understand if monthly subscribers are mostly who are churning or not?\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Contract', hue='Churn', data=df)\n",
        "plt.title('Contract Type vs. Churn')\n",
        "plt.xlabel('Contract Type')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JSbAm1ESsBFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if the customers who churn doesn't have technical support, internet service, backup, or a yearly contract\n",
        "cols = ['InternetService',\"TechSupport\",\"OnlineBackup\",\"Contract\"]\n",
        "\n",
        "plt.figure(figsize=(14,4))\n",
        "\n",
        "for i, col in enumerate(cols):\n",
        "    ax = plt.subplot(1, len(cols), i+1)\n",
        "    sns.countplot(x =\"Churn\", hue = str(col), data = df)\n",
        "    ax.set_title(f\"{col}\")\n"
      ],
      "metadata": {
        "id": "v4jJvYxXheXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# continue data preperation and make sure the 'Churn' column is numerical (0 and 1)\n",
        "df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})\n",
        "\n",
        "# check if there is a correlation between tenure and churn and Calculate the correlation between them\n",
        "correlation = df['tenure'].corr(df['Churn'])\n",
        "print(f\"Correlation between tenure and churn: {correlation}\")\n",
        "\n",
        "# creat a heatmap to visualize the correlation matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df[['tenure', 'Churn']].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix: Tenure vs. Churn')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O0ECIqVi86Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Select only numeric columns for correlation analysis\n",
        "numerical_df = df.select_dtypes(include=['number'])\n",
        "\n",
        "# Calculate the correlation matrix for numeric columns\n",
        "correlation_matrix = numerical_df.corr()\n",
        "\n",
        "# creating the heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Vy4y3vAr1LGW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the data before building and training the model - a test step\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "# Assuming 'df' is your original DataFrame\n",
        "cat_features = df.select_dtypes(include=['object'])  # Select categorical features\n",
        "\n",
        "df_cat = cat_features.apply(le.fit_transform)\n",
        "df_cat.head()"
      ],
      "metadata": {
        "id": "XnrlSqqAgths"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-assuring the data is cleaned - clean the data and create a logistic regression model that predicts if the customer will churn or not\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# double-check - this step is not necessary here as it was completed above. convert TotalCharges to numeric, coercing errors to NaN and removing NaNs\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(subset=['TotalCharges'], inplace=True)\n",
        "df = df[df['TotalCharges'] != 0] # Remove rows with TotalCharges equal to zero\n",
        "\n",
        "#change the 'SeniorCitizen' to bool\n",
        "df['SeniorCitizen'] = df['SeniorCitizen'].astype(bool)\n",
        "\n",
        "# encode categorical features and convert the categorical variables to numeric\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "\n",
        "# Feature Scaling to standarize the range of the independent variable\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "# Split data into training and testing sets (80% for training, 20% for testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000) # Increased max_iter to ensure convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# test predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# check and evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Replace 'pipeline' with 'model' to use the trained Logistic Regression model\n",
        "y_pred = model.predict(X_test) # Changed line\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "#re-print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7-1GRRoNaLLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a randomforrest model to test the above data and compare the results with the logistic model\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined from the logistic regression part\n",
        "\n",
        "# Initialize and train a RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "\n",
        "# Compare with Logistic Regression results (assuming 'accuracy' from logistic regression is available)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy}\")\n",
        "\n",
        "#Further evaluation with other metrics\n",
        "print(classification_report(y_test, rf_predictions))\n",
        "print(confusion_matrix(y_test, rf_predictions))"
      ],
      "metadata": {
        "id": "WBqXAT_7iQcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a linear regression model\n",
        "\n",
        "# Import necessary libraries (if not already imported)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assuming 'df' and feature/target variables are defined as in the previous code\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop('Churn', axis=1)  # Replace 'Churn' with your target variable column name\n",
        "y = df['Churn']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "id": "tHfgbTtDiVBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}